{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de08691d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "903\n",
      "903\n",
      "903\n",
      "903\n",
      "903\n",
      "903\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm\n",
    "from molfeat.trans.graph.adj import PYGGraphTransformer\n",
    "from molfeat.calc.atom import AtomCalculator\n",
    "from molfeat.calc.bond import EdgeMatCalculator\n",
    "\n",
    "f = open(\"dc50_labels.txt\", \"r\")\n",
    "lines = f.readlines()\n",
    "refined_lines = []\n",
    "for l in lines:\n",
    "    l = l.replace(\"(n/a)\", \"\")\n",
    "    l = l.replace(\"\\n\", \"\")\n",
    "    l = l.replace(\">\", \"\")\n",
    "    l = l.replace(\"<\", \"\")\n",
    "    l = l.replace(\"=\", \"\")\n",
    "    refined_lines.append(l)\n",
    "\n",
    "final_labels = []\n",
    "for l in refined_lines:\n",
    "    arr = l.split('/')\n",
    "    if len(arr) > 1:\n",
    "        smallest_so_far = 999999\n",
    "        for el in arr:\n",
    "            if el == \"\":\n",
    "                continue\n",
    "            if el.find(\"~\") > 0 or el.find(\"-\") > 0:\n",
    "                continue\n",
    "            el = float(el)\n",
    "            if el < smallest_so_far:\n",
    "                smallest_so_far = el\n",
    "        final_labels.append(smallest_so_far)\n",
    "    else:\n",
    "        final_labels.append(arr[0])\n",
    "\n",
    "target_proteins = np.array(list(df[\"Target Protein\"]))\n",
    "e3_targets = np.array(list(df[\"E3 Target\"]))\n",
    "warheads = np.array(list(df[\"Warhead\"]))\n",
    "linkers = np.array(list(df[\"Linker\"]))\n",
    "e3_ligands = np.array(list(df[\"E3 Ligand\"]))\n",
    "\n",
    "labeled_indices = []\n",
    "for i, val in enumerate(final_labels):\n",
    "    val = str (val)\n",
    "    if val == \"\":\n",
    "        continue\n",
    "    else:\n",
    "        labeled_indices.append(i)\n",
    "        \n",
    "target_proteins = target_proteins[labeled_indices]\n",
    "e3_targets = e3_targets[labeled_indices]\n",
    "warheads = warheads[labeled_indices]\n",
    "linkers = linkers[labeled_indices]\n",
    "e3_ligands = e3_ligands[labeled_indices]\n",
    "final_labels = np.array(final_labels)\n",
    "my_labels = final_labels[labeled_indices]\n",
    "\n",
    "print(len(target_proteins))\n",
    "print(len(e3_targets))\n",
    "print(len(warheads))\n",
    "print(len(linkers))\n",
    "print(len(e3_ligands))\n",
    "print(len(my_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3142d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm as tqdm\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit.Chem import DataStructs\n",
    "from Bio.SeqUtils.ProtParam import ProteinAnalysis\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "from itertools import product\n",
    "\n",
    "def sequence_to_kmer(protein_seq, k):\n",
    "    groups={'A':'1','V':'1','G':'1','I':'2','L':'2','F':'2','P':'2','Y':'3',\n",
    "            'M':'3','T':'3','S':'3','H':'4','N':'4','Q':'4','W':'4',\n",
    "            'R':'5','K':'5','D':'6','E':'6','C':'7'}\n",
    "    crossproduct=[''.join (i) for i in product(\"1234567\",repeat=k)]\n",
    "    for i in range(0, len(crossproduct)): crossproduct[i]=int(crossproduct[i])\n",
    "    ind=[]\n",
    "    for i in range(0, len(crossproduct)): ind.append(i)\n",
    "    combinations=dict(zip(crossproduct, ind))\n",
    "    \n",
    "    V=np.zeros(int((math.pow(7,k))))\n",
    "    try:\n",
    "        for j in range(0, len(protein_seq)-k+1):\n",
    "            kmer=protein_seq[j:j+k]\n",
    "            c=''\n",
    "            for l in range(0, k):\n",
    "                c+=groups[kmer[l]]\n",
    "                V[combinations[int(c)]] += 1\n",
    "    except:\n",
    "        count={'1':0,'2':0,'3':0, '4':0, '5':0,'6':0,'7':0}\n",
    "        for q in range(0,len(protein_seq)):\n",
    "            if protein_seq[q]=='A' or protein_seq[q]=='V' or protein_seq[q]=='G':\n",
    "                count['1']+=1\n",
    "            if protein_seq[q]=='I' or protein_seq[q]=='L'or protein_seq[q]=='F' or protein_seq[q]=='P':\n",
    "                count['2']+=1\n",
    "            if protein_seq[q]=='Y' or protein_seq[q]=='M'or protein_seq[q]=='T' or protein_seq[q]=='S':\n",
    "                count['3']+=1\n",
    "            if protein_seq[q]=='H' or protein_seq[q]=='N'or protein_seq[q]=='Q' or protein_seq[q]=='W':\n",
    "                count['4']+=1\n",
    "            if protein_seq[q]=='R' or protein_seq[q]=='K':\n",
    "                count['5']+=1\n",
    "            if protein_seq[q]=='D' or protein_seq[q]=='E':\n",
    "                count['6']+=1\n",
    "            if protein_seq[q]=='C':\n",
    "                count['7']+=1\n",
    "        \n",
    "        value=list(count.values())\n",
    "        key=list(count.keys())\n",
    "        maximum_occurence=0\n",
    "        index=0\n",
    "        for t in range(0, len(value)):\n",
    "            if maximum_occurence < value[t]:\n",
    "                maximum_occurence = value[t]\n",
    "                index=t\n",
    "        maximum_occurence = key[index] # group number of maximum occuring group\n",
    "        for j in range(0, len(protein_seq)-k+1):\n",
    "            kmer=protein_seq[j:j+k]\n",
    "            c=''\n",
    "            for l in range(0, k):\n",
    "                if kmer[l] not in groups:\n",
    "                    c += maximum_occurence\n",
    "                else:\n",
    "                    c+=groups[kmer[l]]\n",
    "            V[combinations[int(c)]] += 1\n",
    "            \n",
    "        V = V/(len(protein_seq)-1)\n",
    "        return np.array(V)\n",
    "    \n",
    "\n",
    "def get_protein_features(protein_sequence):\n",
    "    aa=['A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y']\n",
    "    f = []\n",
    "    protein_info = ProteinAnalysis(str(protein_sequence))\n",
    "    protein_info.molecular_weight()\n",
    "    amino_acid_percent = protein_info.get_amino_acids_percent()\n",
    "    dp = []\n",
    "    for a in aa:\n",
    "        dp.append(amino_acid_percent[a])\n",
    "    dp=np.array(dp)\n",
    "    dp=normalize(np.atleast_2d(dp), norm='l2', copy=True, axis=1, return_norm=False)\n",
    "    f.extend(dp[0])\n",
    "    twomer=np.array(sequence_to_kmer(str(protein_sequence), 2))\n",
    "    twomer=normalize(np.atleast_2d(twomer), norm='l2', copy=True, axis=1,return_norm=False)\n",
    "    f.extend(twomer[0])\n",
    "    threemer=np.array(sequence_to_kmer(str(protein_sequence), 3))\n",
    "    threemer=normalize(np.atleast_2d(threemer), norm='l2', copy=True, axis=1,return_norm=False)\n",
    "    f.extend(threemer[0])\n",
    "    return np.array(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "719a6740",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 903/903 [00:06<00:00, 143.36it/s]\n"
     ]
    }
   ],
   "source": [
    "labels = []\n",
    "for m in my_labels:\n",
    "    if m.find(\"~\") > 0:\n",
    "        m.split(\"~\")\n",
    "        m = float (m[0])\n",
    "        labels.append(m)\n",
    "    elif m.find(\"-\") > 0:\n",
    "        m.split(\"-\")\n",
    "        m = float (m[0])\n",
    "        labels.append(m)\n",
    "    else:\n",
    "        m = float (m)\n",
    "        labels.append(m)\n",
    "\n",
    "target_protein_features = []\n",
    "e3_target_features = []\n",
    "\n",
    "for i in tqdm(range(len(target_proteins))):\n",
    "    p = get_protein_features(target_proteins[i])\n",
    "    et = get_protein_features(e3_targets[i])\n",
    "    \n",
    "    target_protein_features.append(p)\n",
    "    e3_target_features.append(et)\n",
    "    \n",
    "target_protein_features = np.array(target_protein_features)\n",
    "e3_target_features = np.array(e3_target_features)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b2ff124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(903,)\n"
     ]
    }
   ],
   "source": [
    "labels = np.array(labels)\n",
    "labels = np.log(labels)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b11a0402",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch_geometric.utils import degree\n",
    "\n",
    "featurizer = PYGGraphTransformer(\n",
    "    atom_featurizer=AtomCalculator(), \n",
    "    bond_featurizer=EdgeMatCalculator()\n",
    ")\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, smiles, labels, featurizer):\n",
    "        super().__init__()\n",
    "        self.smiles = smiles\n",
    "        self.featurizer = featurizer\n",
    "        self.featurizer.auto_self_loop()\n",
    "        self.labels = torch.tensor(labels).unsqueeze(-1).float()\n",
    "        self.transformed_mols = self.featurizer(smiles)\n",
    "        self._degrees = None\n",
    "        \n",
    "    @property\n",
    "    def num_atom_features(self):\n",
    "        return self.featurizer.atom_dim\n",
    "    \n",
    "    @property\n",
    "    def num_output(self):\n",
    "        return self.labels.shape[-1]\n",
    "    \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.transformed_mols)\n",
    "    \n",
    "    \n",
    "    @property\n",
    "    def degree(self):\n",
    "        if self._degrees is None:\n",
    "            max_degree = -1\n",
    "            for data in self.transformed_mols:\n",
    "                d = degree(data.edge_index[1], num_nodes=data.num_nodes, dtype=torch.long)\n",
    "                max_degree = max(max_degree, int(d.max()))\n",
    "            deg = torch.zeros(max_degree+1, dtype=torch.long)\n",
    "            for data in self.transformed_mols:\n",
    "                d = degree(data.edge_index[1], num_nodes=data.num_nodes, dtype=torch.long)\n",
    "                deg += torch.bincount(d, minlength=deg.numel())\n",
    "            self._degrees = deg\n",
    "        return self._degrees\n",
    "    \n",
    "    def collate_fn(self, **kwargs):\n",
    "        return self.featurizer.get_collate_fn(**kwargs)\n",
    "    \n",
    "    \n",
    "    def __get_item__(self, index):\n",
    "        return self.transformed_mols[index], self.y[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4ff23a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MyDataset(df.Warhead.values, labels, featurizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c757506d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
